{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lacave91/lab-neural-networks/blob/master/your-code/challenge-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv7EVNhTJu7Y"
      },
      "source": [
        "# Challenge 1 - Tic Tac Toe\n",
        "\n",
        "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
        "\n",
        "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
        "\n",
        "![Tic Tac Toe Grids](https://github.com/Lacave91/lab-neural-networks/blob/master/your-code/tttboard.jpg?raw=1)\n",
        "\n",
        "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJIgykhJu7a"
      },
      "source": [
        "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
        "\n",
        "## Step 1: Data Engineering\n",
        "\n",
        "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
        "\n",
        "1. Read `tic-tac-toe.csv` into a dataframe.\n",
        "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
        "1. Convert the categorical values to numeric in all columns.\n",
        "1. Separate the inputs and output.\n",
        "1. Normalize the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyhYnbN9Ju7b",
        "outputId": "80b6b6fc-594b-4795-f108-67b2a980c0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    TL TM TR ML MM MR BL BM BR  class\n",
            "0    x  x  x  x  o  o  x  o  o   True\n",
            "1    x  x  x  x  o  o  o  x  o   True\n",
            "2    x  x  x  x  o  o  o  o  x   True\n",
            "3    x  x  x  x  o  o  o  b  b   True\n",
            "4    x  x  x  x  o  o  b  o  b   True\n",
            "..  .. .. .. .. .. .. .. .. ..    ...\n",
            "953  o  x  x  x  o  o  o  x  x  False\n",
            "954  o  x  o  x  x  o  x  o  x  False\n",
            "955  o  x  o  x  o  x  x  o  x  False\n",
            "956  o  x  o  o  x  x  x  o  x  False\n",
            "957  o  o  x  x  x  o  o  x  x  False\n",
            "\n",
            "[958 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"tic-tac-toe.csv\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "# Inspect the dataset\n",
        "print(df.head())  # Display the first few rows\n",
        "print(df.info())  # Check for missing values and data types\n",
        "print(df['class'].value_counts())  # Check class distribution\n",
        "\n",
        "# Convert categorical values to numeric\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Separate inputs and output\n",
        "X = df.drop(columns=['class'])  # Input features\n",
        "y = df['class']  # Target variable\n",
        "\n",
        "#  Normalize the input data\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Convert back to DataFrame for better readability\n",
        "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
        "\n",
        "# Display processed data\n",
        "print(X_normalized_df.head())\n",
        "print(y.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neqbwri3QHrg",
        "outputId": "32f90ff7-49b8-426e-d89b-76b18c159955"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  TL TM TR ML MM MR BL BM BR  class\n",
            "0  x  x  x  x  o  o  x  o  o   True\n",
            "1  x  x  x  x  o  o  o  x  o   True\n",
            "2  x  x  x  x  o  o  o  o  x   True\n",
            "3  x  x  x  x  o  o  o  b  b   True\n",
            "4  x  x  x  x  o  o  b  o  b   True\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 958 entries, 0 to 957\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   TL      958 non-null    object\n",
            " 1   TM      958 non-null    object\n",
            " 2   TR      958 non-null    object\n",
            " 3   ML      958 non-null    object\n",
            " 4   MM      958 non-null    object\n",
            " 5   MR      958 non-null    object\n",
            " 6   BL      958 non-null    object\n",
            " 7   BM      958 non-null    object\n",
            " 8   BR      958 non-null    object\n",
            " 9   class   958 non-null    bool  \n",
            "dtypes: bool(1), object(9)\n",
            "memory usage: 68.4+ KB\n",
            "None\n",
            "class\n",
            "True     626\n",
            "False    332\n",
            "Name: count, dtype: int64\n",
            "    TL   TM   TR   ML   MM   MR   BL   BM   BR\n",
            "0  1.0  1.0  1.0  1.0  0.5  0.5  1.0  0.5  0.5\n",
            "1  1.0  1.0  1.0  1.0  0.5  0.5  0.5  1.0  0.5\n",
            "2  1.0  1.0  1.0  1.0  0.5  0.5  0.5  0.5  1.0\n",
            "3  1.0  1.0  1.0  1.0  0.5  0.5  0.5  0.0  0.0\n",
            "4  1.0  1.0  1.0  1.0  0.5  0.5  0.0  0.5  0.0\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbO-iMXZJu7b"
      },
      "source": [
        "## Step 2: Build Neural Network\n",
        "\n",
        "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
        "\n",
        "1. Split the training and test data.\n",
        "1. Create a `Sequential` model.\n",
        "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
        "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
        "1. Fit the training data.\n",
        "1. Evaluate your neural network model with the test data.\n",
        "1. Save your model as `tic-tac-toe.model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-fP6kf5Ju7c",
        "outputId": "7d277c54-92c9-463e-f0d1-94278ccbff5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.4655\n",
            "Epoch 2/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1072\n",
            "Epoch 3/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0687\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7965edf87e50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "(x_train) = tf.keras.utils.normalize(x_train, axis=1)\n",
        "(x_test) = tf.keras.utils.normalize(x_test, axis=1)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8sAkvKSXkWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6UBg_AqkRxr9",
        "outputId": "f1936e00-9728-4a48-e185-2a0c85926266"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
            "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
            "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
            "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
            "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
            "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
            "  0.33153488 0.11664776 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.20500962\n",
            "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01622378\n",
            "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
            "  0.04089933 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
            "  0.245396   0.05882702 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
            "  0.41390126 0.40743158 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.32161793\n",
            "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
            "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
            "  0.40899334 0.39653769 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.04117838 0.16813739\n",
            "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
            "  0.12760592 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
            "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.37491383 0.56222061\n",
            "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
            "  0.17428513 0.01425695 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92705966 0.82698729\n",
            "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVWFkA8uJu7c"
      },
      "source": [
        "## Step 3: Make Predictions\n",
        "\n",
        "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyLBum8VJu7c",
        "outputId": "e1868cf4-8f06-4460-ad80-9abd3dc6a303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0945\n",
            "0.08627969026565552 0.9728000164031982\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "print(val_loss, val_acc)\n",
        "model.save(\"/tic-tac-toe_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1IlO2AUJu7c"
      },
      "source": [
        "## Step 4: Improve Your Model\n",
        "\n",
        "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
        "\n",
        "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
        "\n",
        "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
        "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
        "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
        "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
        "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "6ym1-tZ1Ju7c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "model_tic_tac_toe = keras.models.load_model(\"/tic-tac-toe_model.keras\", custom_objects={'softmax_v2': tf.nn.softmax})\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_tic_tac_toe.predict([x_test])"
      ],
      "metadata": {
        "id": "0mazzqG1jCSg",
        "outputId": "d0d8be4c-e8a3-403e-b6b6-8a3f7eedb580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7joavO7ajQY",
        "outputId": "556a5ac9-e323-4990-bc87-849ea3dd06a9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.68314107e-09 7.80172726e-09 5.12535007e-06 ... 9.99887347e-01\n",
            "  9.16803202e-08 3.94411472e-06]\n",
            " [7.09754431e-07 2.18179237e-04 9.99766648e-01 ... 2.71823257e-08\n",
            "  1.30003571e-07 7.93699717e-10]\n",
            " [1.81196435e-06 9.98529434e-01 4.51010383e-05 ... 8.82103399e-04\n",
            "  1.19339406e-04 2.55862851e-05]\n",
            " ...\n",
            " [1.77258102e-08 4.31221764e-07 1.10920887e-07 ... 9.87357053e-05\n",
            "  3.03286415e-05 5.01237460e-04]\n",
            " [3.15139841e-05 1.68885265e-06 2.60847696e-06 ... 5.72156205e-05\n",
            "  5.59227774e-04 2.04478283e-06]\n",
            " [2.61114906e-07 5.09936910e-08 1.50299257e-08 ... 5.14340848e-10\n",
            "  2.11975992e-09 3.54678997e-09]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.argmax(predictions[0]))"
      ],
      "metadata": {
        "id": "qNyyfXV1jwhY",
        "outputId": "cf404515-615b-48b2-f0da-3c47fcd93a8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mq5c-lGEjxAz",
        "outputId": "f16e6407-90e2-4c2e-ba1d-f033321b6f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.01,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    loss_scale_factor=None,\n",
        "    gradient_accumulation_steps=None,\n",
        "    name='adam',\n",
        "\n",
        ")\n",
        "model.fit(x_train, y_train, epochs=6)"
      ],
      "metadata": {
        "id": "erWOorSXkiqh",
        "outputId": "66cc8089-87d6-4aad-dafb-4626d0389ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0139\n",
            "Epoch 2/6\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0091\n",
            "Epoch 3/6\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0120\n",
            "Epoch 4/6\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0104\n",
            "Epoch 5/6\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0086\n",
            "Epoch 6/6\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0082\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7965ee489810>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwfIGuG_Ju7c"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=3)**Which approach(es) did you find helpful to improve your model performance?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnsSjPTAJu7c"
      },
      "outputs": [],
      "source": [
        "#I did improve my model raising the \"learning rate\" and the numbers of \"epochs\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HFbDHnvxldCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}